{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_Detection_pool.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGxELduWZ4hTQVKYZq4F4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyShchus/Object-Detection-GisPro/blob/master/Object-Detection-GisPro/Object-Detection-GisPro/project/Detection_pool/Notebooks/Object_Detection_pool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHYnLZnZoSsd",
        "colab_type": "text"
      },
      "source": [
        "# Exercise scenario\n",
        "Tax assessors at local government agencies often rely on surveys to estimate property valueand calculate property taxes. These surveys are infrequent, which means that there can besome inaccuracy in the assessment records. Swimming pools are an important part of theseassessments because they impact the value of the property. You will use ArcGIS deep learningtools to detect all swimming pools in a defined area. Tax assessors can use this information toidentify newly constructed pools that were not recorded in the assessment records. Thisinformation will help tax assessors identify more appropriate property values ​​and taxes, whichcan lead to additional revenue for the community.\n",
        "# Step 1: Download the exercise data files\n",
        "In this step, you will download the exercise data files.\n",
        " Open a new web browser tab or window.\n",
        " Go to https://bit.ly/2FaJ5Wy and download the exercise data ZIP file.Note: The complete URL to the exercise data file is https://www.arcgis.com/home/item.html?id=835d0a54412a45b9b361ce8e0fbd37d4 .\n",
        " Extract the files to a folder on your local computer, saving them in a location that you willremember.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQL6-28PouXg",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Create training samples\n",
        "\n",
        "# Step 3: Export training samples\n",
        "\n",
        "Image chips use the training sample locations to cut, or chip, the source imagery into definedsub images that will contain a training sample. These image chips will be used to train theobject detection deep learning model.\n",
        "\n",
        "In the Geoprocessing pane, search for and open the Export Training Data For DeepLearning (Image Analyst Tools) tool.\n",
        "\n",
        " Complete the tool using the following parameters:\n",
        " • Input Raster: NAIP_AOI.tif\n",
        " • Output Folder: ImageChips\n",
        " • Input Feature Class Or Classified Raster: TrainingSamplesComplete\n",
        " • Class Value Field: ClassValue\n",
        " • Buffer Radius: 6\n",
        " \n",
        "  For Buffer Radius, point to the parameter name and pause your pointer on theGeoprocessing input information icon.\n",
        "\n",
        "  The Geoprocessing Input Information iconprovides an explanation of how the parameteris used in the tool. Because you are using point data, you can use this parameter to add abuffer around each point, creating circular polygon training samples that will better representthe shape of the pools.\n",
        "\n",
        "   For Input Mask Polygons, leave the default.\n",
        "\n",
        "   This parameter delineates the area where image chips will be created. You want to createimage chips for all training samples, so you will leave this parameter empty.e\n",
        "   \n",
        "    For Image Format, leave the default.The image format that you choose will depend on the number of bands of your sourceimagery file.\n",
        "\n",
        "  For Tile Size X and Tile Size Y, leave the defaults.Tile size is the dimensions of the image chip size in X and Y. The unit of measurement is inpixels. Larger tile sizes will require more processing time and power.\n",
        "  \n",
        "  For Stride X and Stride Y, leave the defaults.The stride determines how much overlap there will be in each image chip. With a tile size of256 and a stride of 128, half of the first image chip will overlap with the next image chip. Thisis useful when you have a small training sample size and want to increase the training samplesize.h For Rotation Angle, leave the default.Rotation can be used to create additional image chips. The original chip is rotated by aspecified angle to create additional chips, at additional angles. This process can helpaugment the data.Note: There is no correct tile size, stride, and rotation angle. These values ​​will vary based onyour analysis, source imagery, and computing power. The default values ​​provide a baseline,but it is recommended that you try several variations to determine if your model resultsimprove.\n",
        "  For Reference System, leave the default.Reference System indicates the reference system used to interpret the input image. Becausethis image is pre-processed orthoimagery, it should be processed using Map Space.\n",
        "  For Output No Feature Tiles, leave the default.This parameter allows you to include image chips that do not have any training samples. Inthis analysis, it would create image chips with no pools. These chips can provide more context to the model, identifying objects that may look like a pool but are not. Including falsepositives like these can potentially improve model results but includes additional image chipsto process.\n",
        "   For Meta Data Format, choose PASCAL Visual Object Classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saLeBhShrjEq",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: Install deep learning frameworks\n",
        "\n",
        "To work with the deep learning tools in ArcGIS Pro, you need to install supported deep learning frameworks.\n",
        "\n",
        "To install deep learning packages in ArcGIS Pro, first ensure that ArcGIS Pro is installed. Create a new Python deep learning environment by cloning the default Python environment arcgispro-py3 (while you can use any unique name for your cloned environment, the steps below use deeplearning). Then set up the Python environment provided with your ArcGIS Pro setup. The default Python environment is found in C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\.\n",
        "\n",
        "Next, install the following Python packages: Tensorflow, fast.ai, Keras, Pytorch, Scikit-image, Pillow, and Libtiff. Keep in mind you will be installing specific versions of these packages indicated in the installation steps below. The tools only work with these specific versions. Once the packages are installed, you can swap the ArcGIS Pro environment and use the tools.\n",
        "\n",
        "Follow these steps to set up your machine to use the deep learning tools:\n",
        "\n",
        "Open the Python Command Prompt window.\n",
        "Type the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcFZ4JYDr6cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conda create --name deeplearning --clone arcgispro-py3\n",
        "activate deeplearning\n",
        "conda install tensorflow-gpu=1.14.0\n",
        "conda install keras-gpu=2.2.4\n",
        "conda install scikit-image=0.15.0\n",
        "conda install Pillow=6.1.0\n",
        "conda install fastai=1.0.54\n",
        "conda install pytorch=1.1.0\n",
        "conda install libtiff=4.0.10 --no-deps\n",
        "proswap deeplearning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKpl2EEPsjOa",
        "colab_type": "text"
      },
      "source": [
        "# Step 5: Train the model using a geoprocessing tool\n",
        "\n",
        "Next, you will train the model using a geoprocessing tool in ArcGIS Pro. If you prefer to usethe Python API in a Jupyter Notebook, skip this step and proceed to the Train the modelusing the Python API step.\n",
        "\n",
        " In the Geoprocessing pane, search for and open the Train Deep Learning Model (ImageAnalyst Tools) tool.\n",
        "\n",
        "  Enter the following tool parameters:\n",
        "\n",
        "  • Input Training Data: .. \\ ObjectDetection \\ ImageChips\n",
        "\n",
        "  • Output Model: **PoolsModel_25_SSD**\n",
        "\n",
        "  • Max Epochs: **25**\n",
        "\n",
        "  The number of epochs defines the number of times that the image chips will be processed bythe neural network. The default number of 20 is a baseline to which you can adjust based onthe results of your model.c\n",
        "  \n",
        "   Expand Model Parameters.d For Model Type, choose **Single Shot Detector - Object Detection**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-WMPhMKtJrI",
        "colab_type": "text"
      },
      "source": [
        "# Step 6: Train the model using the Python API\n",
        "\n",
        "[Notebook](https://github.com/SergeyShchus/Object-Detection-GisPro/blob/master/Object-Detection-GisPro%20/%20project/Detection_pool/Notebooks/model_training.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myj9UKdXucBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}